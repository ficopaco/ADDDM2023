---
title: "Case Study 2: Heliotronics Estimating an Experience Curve"
author: "UNIGE - GSEM - Advanced Data-Driven Decision Making"
date: "`r Sys.Date()`"
output: 
  html_document: 
    theme: readable
    highlight: pygments
    toc: true
    toc_float: true
    number_sections: true
---

```{r Setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

> *This analysis was prepared by Francisco Arrieta and Jonathan Edwards.*

------------------------------------------------------------------------

```{r Import Data}
library(data.table)
library(ggplot2)
library(corrplot) #correlation matrix plot
library(olsrr)  #VIF and Tolerance Values
library(dplyr)
library(rcompanion) #histograms with normal curve
library(REdaS) #KMO and Bartlett test
library(psych)
library(gridExtra)
library(kableExtra)
library(knitr)
```

# Data Exploration

```{r}
cel_data <- fread("Data File_Case_Study_Factor Analysis_MD.csv", sep = ",", header = T)


#str(cel_data)
#summary(cel_data)
```


```{r Clean Data}

cel_data <- cel_data[,-c("ownership","intro_q", "intro_b", "intro_d", "defect1")]
cel_data <- cel_data[,-c(57:64)]
#str(cel_data)
cel_data <- na.omit(cel_data)

cel_data_quests <- cel_data[,c(7:39)]
```



```{r}
# plots <- lapply (1:33, function(i){
#   x <- cel_data_quests[,i]
#   
#   ggplot(data.frame(x), aes(x)) +
#     geom_histogram(fill = "red", color = "red", bandwidth = 2)+
#     geom_density(aes(y=0.85*..count..), color = "black", adjust = 4, size = 1) +
#     ggtitle(paste("Question",i))+
#     xlab("Scores")+
#     ylab("Count")+
#     xlim(0,7) +
#     theme_classic()
# })
# 
# grid.arrange(brobs = plots, ncol = 5)


par(mfrow = c(2, 2))
plotNormalHistogram(cel_data$qd1, main = paste("Frequency Distribution of QD1"))
plotNormalHistogram(cel_data$sat1, main = paste("Frequency Distribution of SAT1"))
plotNormalHistogram(cel_data$gender, main = paste("Frequency Distribution of GENDER"))
plotNormalHistogram(cel_data$brandrec, main = paste("Frequency Distribution of BRANDREC"))
```



```{r Correlation matrix}

corr_matrix <- cor(cel_data_quests)
corrplot(as.matrix(corr_matrix), method = "shade", order = "hclust", addrect = 10, tl.col ="black", tl.cex = 0.80)

```

```{r LM and VIF}
KMOTEST <- KMOS(cel_data_quests)
KMOTEST

KMO_val <- KMOTEST$KMO
KMO_val

KMO_list <- data.table("Item" = character(), "Score" = double())
for(i in 1:33){
  KMO_list<- rbindlist(list(KMO_list, list(paste("qd",i, sep=""), KMOTEST$MSA[i])))
}

bart_spher(cel_data_quests)

#color_me <- which(KMO_list < KMOTEST$KMO)

# KMO_list |> 
#   kable() |> 
#   kable_styling() |> 
#   row_spec(color_me, bold = T, color = "white", background = "red")
# 
#display results
KMO_list |> 
  kable() |> 
  kable_minimal() |> 
  row_spec(which(KMO_list[,2]>KMO_val), bold = T, color = "white", background = "#78BE20")

# conditionalColor <- function(x, row, columnOffset, threshold, colorLarger, colorElse) {
#   x[row, (columnOffset+1):ncol(x)] <- cell_spec(
#     x[row, (columnOffset+1):ncol(x)], 
#     color = ifelse(as.numeric(x[row, (columnOffset+1):ncol(x)]) < threshold, 
#                    colorLarger, 
#                    colorElse))
#   return(x)
# }
# conditionalColor(KMO_list, 
#                  row = which(KMO_list[ , 1] > KMOTEST$KMO), 
#                  columnOffset = 2, 
#                  threshold = 100, colorLarger = "green", colorElse = "red") |>
#   knitr::kable(escape = FALSE) |> 
#   kable_styling(bootstrap_options = "striped")


cc <-getwd()
opts_knit$set.root.dir <- cc
opts_knit$get()
```

# Principal Axis Factoring

```{r}
best_factors <- data.table("Factors" = double(), "Amount" = double())
best_eigen <- data.table("Index" = 1:31)

for(i in 1:31){
  print(i)
  temp_paf <- psych::fa(data.table(scale(cel_data_quests[,-c(4,23)])), nfactors = i, rotate = "varimax", scores = T)
  #xx <- length(which(temp_paf$values > 1))
  #xx <- as.numeric(temp_paf$communalities)
  xx <- temp_paf$BIC
  best_eigen <- best_eigen[,paste("Factor_", i, sep=""):= temp_paf$values]
  #best_eigen <- rbindlist(list(best_eigen,list(i,temp_paf$values)))
  best_factors <- rbindlist(list(best_factors,list(i, xx)))
}

ggplot(best_factors, aes(Factors,Amount))+
  geom_line()+
  theme_classic()

best_eigen_melt <- melt(best_eigen ,  id.vars = "Index", variable.name = "Series")

ggplot(best_eigen_melt, aes(Index, value))+
  geom_line(aes(color = Series))+
  xlim(0,12)+
  geom_hline(yintercept=1)+
  theme_classic()


paf1 <- psych::fa(cel_data_quests, nfactors = 8, rotate = "Varimax", scores = T, fm = "pa")
summary(paf1)


plot(paf1$values,xlab="Factor Number",
     ylab="Eigenvalue",
     main="Scree plot",
     cex.lab=1.2,
     cex.axis=1.2,
     cex.main=1.8) +abline(h=1)
```

```{r Total Variance}
pafEigenValue <- paf1$values

pafVariance <- pafEigenValue / ncol(cel_data_quests) * 100

pafSumVariance <- cumsum(pafEigenValue / ncol(cel_data_quests))

pafTotal_Variance_Explained <- cbind(EigenValue = pafEigenValue[pafEigenValue>0],
                                  Variance = pafVariance[pafEigenValue>0],
                                  Total_Variance = pafSumVariance[pafEigenValue>0])

pafTotal_Variance_Explained
```



# Principal Component Analysis

```{r PC analysis 1}

cd_PC0 <- psych::principal(cel_data_quests, nfactors = 5, rotate="varimax", scores=TRUE)

plot(cd_PC0$values,xlab="Factor Number",
     ylab="Eigenvalue",
     main="Scree plot",
     cex.lab=1.2,
     cex.axis=1.2,
     cex.main=1.8) +abline(h=1)


```



```{r Total Variance}
EigenValue <- cd_PC0$values

Variance <- EigenValue / ncol(cel_data_quests) * 100

SumVariance <- cumsum(EigenValue / ncol(cel_data_quests))

Total_Variance_Explained <- cbind(EigenValue = EigenValue[EigenValue>0],
                                  Variance = Variance[EigenValue>0],
                                  Total_Variance = SumVariance[EigenValue>0])

Total_Variance_Explained
```

```{r PC analysis 2}

cd_PC1 <- psych::principal(cel_data_quests, rotate="varimax",nfactors=8, scores=TRUE)

PC1_communalities <- data.frame(sort(cd_PC1$communality))
PC1_communalities
#qd3 has the lowest communality but it is not terribly far away from the other values

plot(cd_PC1$values,xlab="Factor Number",
     ylab="Eigenvalue",
     main="Scree plot",
     cex.lab=1.2,
     cex.axis=1.2,
     cex.main=1.8) +abline(h=1)

print(cd_PC1$loadings, cutoff=0.4, sort=TRUE)

```

```{r Total Variance}
EigenValue1 <- cd_PC1$values

Variance1 <- EigenValue1 / ncol(cel_data_quests) * 100

SumVariance1 <- cumsum(EigenValue1 / ncol(cel_data_quests))

Total_Variance_Explained1 <- cbind(EigenValue = EigenValue1[EigenValue1>0],
                                  Variance = Variance1[EigenValue1>0],
                                  Total_Variance = SumVariance[EigenValue1>0])

Total_Variance_Explained1
```


```{r Regression and factor scores}
cd_factors <- cbind(cel_data_quests,cd_PC1$scores)
colnames(cd_factors)[34:41]=c("Serviceability",
                          "Performance",
                          "Durability",
                          "Aesthetics",
                          "Ease_of_use",
                          "Features",
                          "Reliability",
                          "Prestige")
```

# Oblique Rotation

```{r Oblique Rotation}
cd_oblique2 <- cel_data[,c(7:42, 48:49)]
cd_oblique <- cel_data[, c(40:42, 48:49)]

cd_oblq1 <- psych::principal(cel_data_quests, rotate="promax",nfactors=8, scores=TRUE)
cd_oblq3 <- psych::principal(cel_data_quests[,-c(4,23)], rotate="promax",nfactors=8, scores=TRUE)
cd_oblq2 <- psych::principal(cd_oblique, rotate="promax",nfactors=2, scores=TRUE)


print(cd_oblq3$loadings, cutoff=0.4, sort=TRUE)


cd_oblq1_communalities <- data.frame(sort(cd_oblq1$communality))
cd_oblq1_communalities
#qd3 has the lowest communality but it is not terribly far away from the other values

plot(cd_oblq1$values,xlab="Factor Number",
     ylab="Eigenvalue",
     main="Scree plot",
     cex.lab=1.2,
     cex.axis=1.2,
     cex.main=1.8) +abline(h=1)

print(cd_oblq1$loadings, cutoff=0.4, sort=TRUE)


pred_table <- data.frame(cd_oblq1$scores)
pred_table <- cbind(pred_table,cd_oblq2$scores)


pred_table2 <- data.frame(cd_oblq3$scores)
pred_table2 <- cbind(pred_table,cd_oblq2$scores)
pred_table2 <- cbind(pred_table,cel_data_quests[,c(4,23)])


colnames(pred_table)[1:10]=c("Serviceability",
                          "Performance",
                          "Durability",
                          "Aesthetics",
                          "Ease_of_use",
                          "Features",
                          "Reliability",
                          "Prestige",
                          "Willingness_to_pay",
                          "Repurchase_Intention")

colnames(pred_table2)[1:10]=c("Serviceability",
                          "Performance",
                          "Features",
                          "Aesthetics",
                          "Ease_of_use",
                          "Durability",
                          "Reliability",
                          "Conformance",
                          "Willingness_to_pay",
                          "Repurchase_Intention")

```

```{r Correlation of Factors}
pred_corr_matrix <- cor(pred_table)
corrplot(as.matrix(pred_corr_matrix))

pred_corr_matrix <- cor(pred_table2)
corrplot(as.matrix(pred_corr_matrix))
```

# Regression Analysis

```{r Regression Models}
pred_table <- as.data.table(scale(pred_table))
pred_table2 <- as.data.table(scale(pred_table2))

wtp_model <- lm(Willingness_to_pay ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability + Prestige, data = pred_table)

wtp_model3 <- lm(Willingness_to_pay ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability + Conformance + qd4 + qd23, data = pred_table2)

wtp_model4 <- lm(Willingness_to_pay ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability, data = pred_table2)

wtp_model2 <- lm(Willingness_to_pay ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability + Conformance, data = pred_table2)

summary(wtp_model)
summary(wtp_model2)
summary(wtp_model3)
summary(wtp_model4)

ri_model <- lm(Repurchase_Intention ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability + Prestige, data = pred_table)

ri_model3 <- lm(Repurchase_Intention ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability + Conformance + qd4 + qd23, data = pred_table2)

ri_model4 <- lm(Repurchase_Intention ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability, data = pred_table2)

ri_model2 <- lm(Repurchase_Intention ~ Serviceability +Performance + Durability + Aesthetics + Ease_of_use + Features + Reliability + Conformance, data = pred_table2)

summary(ri_model)
summary(ri_model2)
summary(ri_model3)
summary(ri_model4)
```

```{r}
#create subset of data per brand
#for (i in 1:5){
  #nam <- paste("cd_", as.character(i), sep = "")
  #assign(nam, cel_data[cel_data$brandrec == i,])
  
  #print(as.data.table(nam))
  #xx <- subset(as.data.table(nam), brandrec == i)
  
  #separate the variables
  #temp_quest <- psych::principal(nam, rotate="promax",nfactors=8, scores=TRUE)
  #temp_vars <- psych::principal(nam, rotate="promax",nfactors=2, scores=TRUE)
#}

#xx <- lm(ri_1~ri_2 + brandrec=1, data = cel_data)


```

